# jemdoc: menu{MENU}{index.html} 
= TEASEL: a Transformer-Based Speech-Prefixed Language Model 

~~~
{}{img_left}{teasel_fig_1.png}{alt text}{510}{200}{}
- *Mehdi Arjmand*, Mohammad Javad Dousti, and Hadi Moradi, *"/TEASEL: a Transformer-Based Speech-Prefixed Language Model/"*, arXiv preprint arXiv:2109.05522, 2021
\n [teasel.html Website] | [https://arxiv.org/abs/2109.05522.pdf Arxiv] | [https://github.com/arminarj/teasel Code]
~~~

== Abstract

Multimodal language analysis is a burgeoning field of NLP that aims to simultaneously model a speaker's words, acoustical annotations, and facial expressions. In this area, \n 
lexicon features usually outperform other modalities because they are pre-trained on large corpora via Transformer-based models. Despite their strong performance, training \n 
a new /self-supervised learning/ (SSL) Transformer on any modality is not usually attainable due to insufficient data,  which is the case in multimodal language learning. \n 
This work proposes a /Transformer-Based Speech-Prefixed Language Model/ called TEASEL to approach the mentioned constraints without training a complete Transformer model. \n 
\teasel model includes speech modality as a dynamic prefix besides the textual modality compared to a conventional language model. This method exploits a conventional \n 
pre-trained language model as a cross-modal Transformer model. We evaluated TEASEL for the multimodal sentiment analysis task defined by CMU-MOSI dataset. Extensive experiments \n 
show that our model outperforms unimodal baseline language models by 4\% and outperforms the current /state-of-the-art/ (SoTA) model by 1\% in F1-score. Additionally, our proposed \n 
method is 72\% smaller than the SoTA model.

~~~
{}{img_left}{teasel_fig_2.png}{alt text}{537}{403}{}
~~~

== Citation

~~~
{}
@misc{arjm2021teasel,\n
    title={TEASEL: A Transformer-Based Speech-Prefixed Language Model},\n
    author={Mehdi Arjmand and Mohammad Javad Dousti and Hadi Moradi}, \n
    year={2021},\n
    eprint={2109.05522},\n
    archivePrefix={arXiv},\n
    primaryClass={cs.CL}\n
}

~~~


